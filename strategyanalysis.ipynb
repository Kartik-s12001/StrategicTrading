{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "aUIiFGYHiLae"
      },
      "outputs": [],
      "source": [
        "# %% imports\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns\n",
        "\n",
        "import statsmodels.api as sm\n",
        "from statsmodels.tsa.stattools import adfuller\n",
        "from statsmodels.graphics.tsaplots import plot_acf\n",
        "from statsmodels.formula.api import ols\n",
        "import scipy.stats as stats\n",
        "import openpyxl\n",
        "\n",
        "\n",
        "# %% user_defined functions used in this script\n",
        "\n",
        "def expanding_z_score(seq, warmup=60):\n",
        "    \"\"\" Returns a Series or  DataFrame of z-scores calculated on an expanding window with a warmup period.\n",
        "\n",
        "    Args:\n",
        "        seq(Series or DataFrame): a sequence of values for which a z-score will be calculated on the expanding window.\n",
        "        warmup(int): The warm-up period is the first period that is used to calculate the first z-score. After that\n",
        "        the z-score is calculated on an expanding window of the sequence: from the very first start value until the\n",
        "         next step.\n",
        "    Returns:\n",
        "        Series or DataFrame: z-scores calculated on an expanding window of values.\n",
        "    \"\"\"\n",
        "    seq = seq.dropna()\n",
        "    average_expanding = seq.expanding(min_periods=warmup).mean()  # expanding mean\n",
        "    std_expanding = seq.expanding(min_periods=warmup).std()  # expanding stdev\n",
        "    z_expanding = (seq - average_expanding) / std_expanding  # the expanding z-score\n",
        "    return z_expanding\n",
        "\n",
        "\n",
        "# %% user defined function for time lagged cross correlations\n",
        "\n",
        "def cross_correlation(target, feature, lag=0):\n",
        "    \"\"\" Returns tuple(s) of Pearson cross-correlation with their p-values of 2 series of\n",
        "     equal length for a given lag in the feature.\n",
        "\n",
        "    Args:\n",
        "        target (Series):Time-series of equal length as feature. Time-series should be stationary (differenced)\n",
        "        feature (Series): Time-series of equal length. Time-series should be stationary (differenced)\n",
        "        lag(int): Lag for the feature time-series\n",
        "    Returns:\n",
        "        List: List of tuple(s) holding the Pearson correlation statistic and the p-value\n",
        "\n",
        "\n",
        "    \"\"\"\n",
        "    feature_shifted = feature.shift(lag).dropna()  # create the lag and drop resulting nan\n",
        "    target_series = target.iloc[lag:]  # make target_series of equal length again with lagged feature\n",
        "\n",
        "    return stats.pearsonr(target_series, feature_shifted)\n",
        "\n",
        "\n",
        "# %% import the xlsx sheets\n",
        "\n",
        "data = pd.read_excel('fx_beer_data.xlsx', engine='openpyxl',\n",
        "                     sheet_name=['fx', 'tot', 'gfc', 'yield', 'cpi', 'prod'])\n",
        "\n",
        "# %% global variables\n",
        "start_date_panel = '1996-04-30'\n",
        "end_date_panel = '2023-02-28'\n",
        "\n",
        "# %% construct df for fx prices: transform fx prices (make aligned time series, resample eom, naming,\n",
        "# base_fx/quote_fx, log of pairs)\n",
        "\n",
        "fx_data = data['fx'].set_index('date')\n",
        "fx_data = fx_data.resample('M').last()\n",
        "\n",
        "# transform all pairs to format base_fx/quote_fx with quote_fx always being usd as reference currency\n",
        "fx_data['cadusd'] = 1 / fx_data.usdcad\n",
        "fx_data['jpyusd'] = 1 / fx_data.usdjpy\n",
        "fx_data['sekusd'] = 1 / fx_data.usdsek\n",
        "fx_data['nokusd'] = 1 / fx_data.usdnok\n",
        "fx_data['chfusd'] = 1 / fx_data.usdchf\n",
        "fx_data['plnusd'] = 1 / fx_data.usdpln\n",
        "fx_data['hufusd'] = 1 / fx_data.usdhuf\n",
        "fx_data['czkusd'] = 1 / fx_data.usdczk\n",
        "\n",
        "# list of tickers needed in final df\n",
        "\n",
        "g12_tickers_conv = ['eurusd', 'usdcad', 'usdjpy', 'gbpusd', 'usdsek', 'usdnok', 'usdchf', 'audusd',\n",
        "                    'nzdusd', 'usdpln', 'usdhuf', 'usdczk']\n",
        "g12_tickers = ['eurusd', 'cadusd', 'jpyusd', 'gbpusd', 'sekusd', 'nokusd', 'chfusd', 'audusd', 'nzdusd',\n",
        "               'plnusd', 'hufusd', 'czkusd']\n",
        "g9_tickers = ['eurusd', 'cadusd', 'jpyusd', 'gbpusd', 'sekusd', 'nokusd', 'chfusd', 'audusd', 'nzdusd']\n",
        "cee3_tickers = ['plnusd', 'hufusd', 'czkusd']\n",
        "\n",
        "# final df for fx prices in log format and correct time_series format\n",
        "fx = fx_data[g12_tickers]\n",
        "fx_log = np.log(fx)\n",
        "fx_log = fx_log.loc[start_date_panel:]\n",
        "\n",
        "print(f'fx_log shape of frame is {fx_log.shape}, \\n'\n",
        "      f'fx_log starts at {fx_log.index.date[0]}, \\n'\n",
        "      f'fx_log ends at {fx_log.index.date[-1]}')\n",
        "\n",
        "# %% plot of conventional quoted fx_pairs\n",
        "\n",
        "fig, ax = plt.subplots(nrows=12, figsize=(7, 9), sharex='all')\n",
        "fig.suptitle('FX evolution since 1996: market convention quotes', fontsize=10)\n",
        "plt.rcParams['font.size'] = 7\n",
        "for index, currency in enumerate(g12_tickers_conv):\n",
        "    ax[index].plot(fx_data[currency], label=currency)\n",
        "    ax[index].legend(loc='upper left', fontsize=7)\n",
        "\n",
        "sns.despine()\n",
        "plt.savefig('fx_chart_convention.png', dpi=300)\n",
        "plt.show()\n",
        "\n",
        "# %% faster way to plot multiple time_series\n",
        "\n",
        "fig.tight_layout()\n",
        "fx_data[g12_tickers].plot(\n",
        "    subplots=True,\n",
        "    layout=(4, 3),\n",
        "    figsize=(10, 6),\n",
        "    title='FX prices quoted in USD',\n",
        "    cmap='tab20',\n",
        "    sharex=False,\n",
        "    sharey=False,\n",
        "    fontsize=6,\n",
        "    linewidth=1,\n",
        "    legend=True,\n",
        ")\n",
        "sns.despine()\n",
        "plt.savefig('fx_chart.png', dpi=300)\n",
        "plt.show()\n",
        "# %% plot of fx_pairs with usd as the quoted currency\n",
        "\n",
        "fig, ax = plt.subplots(nrows=12, figsize=(7, 9), sharex='all')\n",
        "fig.suptitle('FX evolution since 1996: usd as quoted currency', fontsize=10)\n",
        "plt.rcParams['font.size'] = 7\n",
        "for index, currency in enumerate(g12_tickers):\n",
        "    ax[index].plot(fx_data[currency], label=currency)\n",
        "    ax[index].legend(loc='upper left', fontsize=7)\n",
        "sns.despine()\n",
        "plt.savefig('fx_chart.png', dpi=300)\n",
        "plt.show()\n",
        "\n",
        "# %% example of seasonal decompose for a currency level\n",
        "\n",
        "eur_decomp = sm.tsa.seasonal_decompose(fx_data.eurusd)\n",
        "eur_decomp.plot()\n",
        "plt.show()\n",
        "\n",
        "# %% example of seasonal decompose for a currency return\n",
        "\n",
        "# looking at mean log returns per month\n",
        "eurusd_return = fx_log.eurusd.diff().dropna()\n",
        "eur_months = eurusd_return.index.month\n",
        "group = eurusd_return.groupby(eur_months).mean()\n",
        "group.index = pd.to_datetime(group.index, format='%m').strftime('%b')\n",
        "plt.style.use(plt.style.available[-1])\n",
        "ax = group.plot(kind='bar')\n",
        "ax.set_title('Average monthly log performance of EURUSD since 1996')\n",
        "ax.set_ylabel('log return')\n",
        "sns.despine()\n",
        "plt.show()\n",
        "\n",
        "# looking at seasonal decomp figure\n",
        "eur_ret_decomp = sm.tsa.seasonal_decompose(eurusd_return)\n",
        "eur_ret_decomp.plot()\n",
        "plt.show()\n",
        "\n",
        "# %% tests significance of december mean return\n",
        "eur_dec_returns = eurusd_return[eurusd_return.index.month == 12]\n",
        "eur_dec_test = stats.ttest_1samp(eur_dec_returns, 0, alternative='greater')\n",
        "print(eur_dec_test)\n",
        "\n",
        "# %% construct df for relative terms of trade (tot)\n",
        "\n",
        "tot_data = data['tot'].set_index('date')\n",
        "tot_data = tot_data.resample('M').last()\n",
        "\n",
        "tot_index = tot_data.copy()\n",
        "tot_index = tot_index + 100\n",
        "tot_ratio = tot_index.iloc[:, 1:].div(tot_index.usd_tot, axis=0)  # tot relative to USA\n",
        "tot_log_ratio = np.log(tot_ratio).shift(1).dropna()  # take log and shift a month for point in time issues\n",
        "tot_log_ratio = tot_log_ratio.loc[start_date_panel:]\n",
        "\n",
        "print(f'tot_log_ratio shape of frame is {tot_log_ratio.shape}, \\n'\n",
        "      f'tot_log_ratio starts at {tot_log_ratio.index.date[0]}, \\n'\n",
        "      f'tot_log_ratio ends at {tot_log_ratio.index.date[-1]}')\n",
        "\n",
        "# %% plot the relative tot of each currency for data exploration\n",
        "\n",
        "fig, ax = plt.subplots(nrows=12, figsize=(7, 9), sharex='all')\n",
        "fig.suptitle('Relative terms of trade evolution since 1996', fontsize=10)\n",
        "plt.rcParams['font.size'] = 7\n",
        "for index, tot in enumerate(tot_ratio.columns):\n",
        "    ax[index].plot(tot_ratio[tot], label=tot)\n",
        "    ax[index].legend(loc='upper left', fontsize=7)\n",
        "sns.despine()\n",
        "plt.savefig('relative_tot_chart.png', dpi=300)\n",
        "plt.show()\n",
        "\n",
        "\n",
        "# %% nicer plot of\n",
        "\n",
        "fig.tight_layout()\n",
        "tot_ratio.plot(\n",
        "    subplots=True,\n",
        "    layout=(4, 3),\n",
        "    figsize=(10, 6),\n",
        "    title='Relative Terms of Trade vs. US',\n",
        "    cmap='tab20',\n",
        "    sharex=False,\n",
        "    sharey=False,\n",
        "    fontsize=6,\n",
        "    linewidth=1,\n",
        "    legend=True,\n",
        ")\n",
        "sns.despine()\n",
        "plt.show()\n",
        "\n",
        "# %% plot scatter plots of fx_log versus tot_log_ratio\n",
        "\n",
        "fig, ax = plt.subplots(nrows=6, ncols=2, figsize=(7, 9))\n",
        "fig.suptitle('Scatter plots of log(fx) versus log(relative terms of trade)', fontsize=10)\n",
        "plt.rcParams['font.size'] = 7\n",
        "for index, tot in enumerate(tot_log_ratio.columns):\n",
        "    if index <= 5:\n",
        "        sns.scatterplot(ax=ax[index, 0], x=tot_log_ratio[tot], y=fx_log.iloc[:, index], label=tot)\n",
        "        ax[index, 0].legend(loc='lower right', fontsize=7)\n",
        "    else:\n",
        "        sns.scatterplot(ax=ax[(index - 6), 1], x=tot_log_ratio[tot], y=fx_log.iloc[:, index], label=tot)\n",
        "        ax[(index - 6), 1].legend(loc='lower right', fontsize=7)\n",
        "sns.despine()\n",
        "plt.savefig('scatter_fx_tot.png', dpi=300)\n",
        "plt.show()\n",
        "\n",
        "# %% construct df for relative gfc\n",
        "\n",
        "gfc_data = data['gfc'].set_index('date')\n",
        "gfc_data.index = pd.to_datetime(gfc_data.index, format='%Y')\n",
        "gfc_data = gfc_data.resample('A').last()  # resample to end of year\n",
        "gfc_data_monthly = gfc_data.resample('M').last().ffill()  # resample eom & ffill missing\n",
        "gfc_new_date_range = pd.date_range(start='1996-01-31', end=end_date_panel, freq='M')\n",
        "gfc_reindexed = gfc_data_monthly.reindex(gfc_new_date_range, method='ffill')\n",
        "gfc_ratio = gfc_reindexed.iloc[:, 1:].div(gfc_reindexed.usd_gfc, axis=0)  # gfc relative to USA\n",
        "gfc_log_ratio = np.log(gfc_ratio)  # point in time not necessary, already year lag tsss\n",
        "gfc_log_ratio = gfc_log_ratio.loc[start_date_panel:]\n",
        "\n",
        "print(f'gfc_log_ratio shape of frame is {gfc_log_ratio.shape}, \\n'\n",
        "      f'gfc_log_ratio starts at {gfc_log_ratio.index.date[0]}, \\n'\n",
        "      f'gfc_log_ratio ends at {gfc_log_ratio.index.date[-1]}')\n",
        "\n",
        "# %% plot the relative gfc of each currency for data exploration\n",
        "\n",
        "fig, ax = plt.subplots(nrows=12, figsize=(7, 9), sharex='all')\n",
        "fig.suptitle('Relative Gross Fixed Capital % GDP evolution since 1996', fontsize=10)\n",
        "plt.rcParams['font.size'] = 7\n",
        "for index, gfc in enumerate(gfc_ratio.columns):\n",
        "    ax[index].plot(gfc_ratio[gfc], label=gfc)\n",
        "    ax[index].legend(loc='upper left', fontsize=7)\n",
        "sns.despine()\n",
        "plt.savefig('relative_gfc_chart.png', dpi=300)\n",
        "plt.show()\n",
        "\n",
        "# %% nicer plot of gfc ratio\n",
        "\n",
        "fig.tight_layout()\n",
        "gfc_ratio.plot(\n",
        "    subplots=True,\n",
        "    layout=(4, 3),\n",
        "    figsize=(10, 6),\n",
        "    title='Relative Gross Fixed Capital Formation as % of GDP vs. US',\n",
        "    cmap='tab20',\n",
        "    sharex=False,\n",
        "    sharey=False,\n",
        "    fontsize=6,\n",
        "    linewidth=1,\n",
        "    legend=True,\n",
        ")\n",
        "sns.despine()\n",
        "plt.show()\n",
        "\n",
        "# %% plot scatter plots of fx_log versus gfc_log_ratio\n",
        "\n",
        "fig, ax = plt.subplots(nrows=6, ncols=2, figsize=(7, 9))\n",
        "fig.suptitle('Scatter plots of log(fx) versus log(relative Gross Fixed Capital as % GDP)', fontsize=10)\n",
        "plt.rcParams['font.size'] = 7\n",
        "for index, gfc in enumerate(gfc_log_ratio.columns):\n",
        "    if index <= 5:\n",
        "        sns.scatterplot(ax=ax[index, 0], x=gfc_log_ratio[gfc], y=fx_log.iloc[:, index], label=gfc)\n",
        "        ax[index, 0].legend(loc='lower right', fontsize=7)\n",
        "    else:\n",
        "        sns.scatterplot(ax=ax[(index - 6), 1], x=gfc_log_ratio[gfc], y=fx_log.iloc[:, index], label=gfc)\n",
        "        ax[(index - 6), 1].legend(loc='lower right', fontsize=7)\n",
        "sns.despine()\n",
        "plt.savefig('scatter_fx_gfc.png', dpi=300)\n",
        "plt.show()\n",
        "\n",
        "# %% construct df for yield for g9 and cee3 (different starting dates which in the end will create unbalanced panel)\n",
        "\n",
        "g9_yield_data = data['yield'].iloc[:, :11].set_index('date')\n",
        "g9_yield_data_monthly = g9_yield_data.resample('M').last()\n",
        "g9_yield_diff = g9_yield_data_monthly.iloc[:, 1:].sub(g9_yield_data_monthly.usd_yield, axis=0)  # yield diff with  USA\n",
        "g9_yield_diff = g9_yield_diff.loc[start_date_panel:]\n",
        "\n",
        "print(f'g9_yield_diff shape of frame is {g9_yield_diff.shape}, \\n'\n",
        "      f'g9_yield_diff starts at {g9_yield_diff.index.date[0]}, \\n'\n",
        "      f'g9_yield_diff ends at {g9_yield_diff.index.date[-1]}')\n",
        "\n",
        "cee3_yield_data = data['yield'].iloc[:, 11:15].set_index('date.1')\n",
        "cee3_yield_data.index.name = 'date'\n",
        "cee3_yield_data_monthly = cee3_yield_data.resample('M').last()\n",
        "cee3_yield_diff = cee3_yield_data_monthly.sub(g9_yield_data_monthly['2001':].usd_yield, axis=0)  # yield diff with  USA\n",
        "cee3_yield_diff = cee3_yield_diff.loc['2001-01-31':]\n",
        "\n",
        "# point in time not necessary here\n",
        "\n",
        "print(f'cee3_yield_diff shape of frame is {cee3_yield_diff.shape}, \\n'\n",
        "      f'cee3_yield_diff starts at {cee3_yield_diff.index.date[0]}, \\n'\n",
        "      f'cee3_yield_diff ends at {cee3_yield_diff.index.date[-1]}')\n",
        "\n",
        "# %% plot the yield_diff of each currency for data exploration\n",
        "\n",
        "fig, ax = plt.subplots(nrows=12, figsize=(6, 9), sharex='all')\n",
        "fig.suptitle('Yield Differential with USA since 1996', fontsize=10)\n",
        "plt.rcParams['font.size'] = 7\n",
        "for index, yield_diff in enumerate(g9_yield_diff.columns):\n",
        "    ax[index].plot(g9_yield_diff[yield_diff], label=yield_diff)\n",
        "    ax[index].legend(loc='upper left', fontsize=7)\n",
        "for index, yield_diff in enumerate(cee3_yield_diff.columns):\n",
        "    ax[index + 9].plot(cee3_yield_diff[yield_diff], label=yield_diff)\n",
        "    ax[index + 9].legend(loc='upper left', fontsize=7)\n",
        "sns.despine()\n",
        "plt.savefig('yield_diff_chart.png', dpi=300)\n",
        "plt.show()\n",
        "\n",
        "# %% nicer plot of yield diff\n",
        "\n",
        "fig.tight_layout()\n",
        "g9_yield_diff.plot(\n",
        "    subplots=True,\n",
        "    layout=(4, 3),\n",
        "    figsize=(10, 6),\n",
        "    title='10Y Yield Difference vs. US',\n",
        "    cmap='tab20',\n",
        "    sharex=False,\n",
        "    sharey=False,\n",
        "    fontsize=6,\n",
        "    linewidth=1,\n",
        "    legend=True,\n",
        ")\n",
        "sns.despine()\n",
        "plt.show()\n",
        "\n",
        "# %% nicer plot of yield diff\n",
        "\n",
        "fig.tight_layout()\n",
        "cee3_yield_diff.plot(\n",
        "    subplots=True,\n",
        "    layout=(4, 3),\n",
        "    figsize=(10, 6),\n",
        "    title='10Y Yield Difference vs. US',\n",
        "    cmap='tab20',\n",
        "    sharex=False,\n",
        "    sharey=False,\n",
        "    fontsize=6,\n",
        "    linewidth=1,\n",
        "    legend=True,\n",
        ")\n",
        "sns.despine()\n",
        "plt.show()\n",
        "\n",
        "# %% plot scatter plots of fx_log versus yield_diff\n",
        "\n",
        "fig, ax = plt.subplots(nrows=6, ncols=2, figsize=(7, 9))\n",
        "fig.suptitle('Scatter plots of log(fx) versus 10y yield differentials', fontsize=10)\n",
        "plt.rcParams['font.size'] = 7\n",
        "for index, yield_diff in enumerate(g9_yield_diff.columns):\n",
        "    if index <= 5:\n",
        "        sns.scatterplot(ax=ax[index, 0], x=g9_yield_diff[yield_diff], y=fx_log.iloc[:, index], label=yield_diff)\n",
        "        ax[index, 0].legend(loc='lower right', fontsize=7)\n",
        "    else:\n",
        "        sns.scatterplot(ax=ax[(index - 6), 1], x=g9_yield_diff[yield_diff], y=fx_log.iloc[:, index], label=yield_diff)\n",
        "        ax[(index - 6), 1].legend(loc='lower right', fontsize=7)\n",
        "for index, yield_diff in enumerate(cee3_yield_diff.columns):\n",
        "    if index <= 5:\n",
        "        sns.scatterplot(ax=ax[index + 3, 1], x=cee3_yield_diff[yield_diff], y=fx_log.iloc[:, index + 9],\n",
        "                        label=yield_diff)\n",
        "        ax[index + 3, 1].legend(loc='lower right', fontsize=7)\n",
        "\n",
        "sns.despine()\n",
        "plt.savefig('scatter_fx_yielddiff.png', dpi=300)\n",
        "plt.show()\n",
        "\n",
        "# %% construct df for log cpi ratio\n",
        "\n",
        "cpi_data = data['cpi'].iloc[:, :12].set_index('date')\n",
        "cpi_data = cpi_data.resample('M').last()\n",
        "cpi_new_date_range = pd.date_range(start='1996-01-31', end=end_date_panel, freq='M')\n",
        "cpi_reindexed = cpi_data.reindex(cpi_new_date_range)\n",
        "cpi_reindexed = cpi_reindexed.ffill()\n",
        "cpi_ratio = cpi_reindexed.iloc[:, 1:].div(cpi_reindexed.usd_cpi, axis=0)  # relative cpi\n",
        "cpi_log_ratio = np.log(cpi_ratio)  # take log, wait to shift for point in time, add nzd & aud first\n",
        "\n",
        "cpi_data_audnzd = data['cpi'].iloc[:, 12:].set_index('date.1')\n",
        "cpi_data_audnzd = cpi_data_audnzd.loc[:'2022-12-30']\n",
        "cpi_data_audnzd_monthly = cpi_data_audnzd.resample('M').last().ffill()\n",
        "cpi_data_audnzd_monthly_reindexed = cpi_data_audnzd_monthly.reindex(cpi_new_date_range)\n",
        "cpi_data_audnzd_monthly_reindexed = cpi_data_audnzd_monthly_reindexed.ffill()\n",
        "cpi_data_audnzd_ratio = cpi_data_audnzd_monthly_reindexed.div(cpi_reindexed.usd_cpi, axis=0)\n",
        "cpi_audnzd_log_ratio = np.log(cpi_data_audnzd_ratio)\n",
        "\n",
        "cpi_log_ratio = cpi_log_ratio.join(cpi_audnzd_log_ratio)\n",
        "cpi_log_ratio = cpi_log_ratio.shift(1).dropna()  # make point in time and lag a month\n",
        "cpi_log_ratio = cpi_log_ratio[['eur_cpi', 'cad_cpi', 'jpy_cpi', 'gbp_cpi', 'sek_cpi',\n",
        "                               'nok_cpi', 'chf_cpi', 'aud_cpi', 'nzd_cpi', 'pln_cpi',\n",
        "                               'huf_cpi', 'czk_cpi']]  # reorder columns just for my sake of mind\n",
        "cpi_log_ratio = cpi_log_ratio.loc[start_date_panel:]\n",
        "\n",
        "print(f'cpi_log_ratio shape of frame is {cpi_log_ratio.shape}, \\n'\n",
        "      f'cpi_log_ratio starts at {cpi_log_ratio.index.date[0]}, \\n'\n",
        "      f'cpi_log_ratio ends at {cpi_log_ratio.index.date[-1]}')\n",
        "\n",
        "# %% plot the relative cpi of each currency for data visualisation\n",
        "\n",
        "fig, ax = plt.subplots(nrows=12, figsize=(7, 9), sharex='all')\n",
        "fig.suptitle('Relative CPI index versus USA since 1996', fontsize=10)\n",
        "plt.rcParams['font.size'] = 7\n",
        "for index, cpi in enumerate(cpi_log_ratio.columns):\n",
        "    ax[index].plot(cpi_log_ratio[cpi], label=cpi)\n",
        "    ax[index].legend(loc='upper left', fontsize=7)\n",
        "sns.despine()\n",
        "plt.savefig('relative_cpi_chart.png', dpi=300)\n",
        "plt.show()\n",
        "\n",
        "# %% nicer plot of cpi ratio\n",
        "\n",
        "fig.tight_layout()\n",
        "cpi_log_ratio.plot(\n",
        "    subplots=True,\n",
        "    layout=(4, 3),\n",
        "    figsize=(10, 6),\n",
        "    title='log cpi ratio vs. US',\n",
        "    cmap='tab20',\n",
        "    sharex=False,\n",
        "    sharey=False,\n",
        "    fontsize=6,\n",
        "    linewidth=1,\n",
        "    legend=True,\n",
        ")\n",
        "sns.despine()\n",
        "plt.show()\n",
        "\n",
        "# %% plot scatter plots of fx_log versus cpi_log_ratio\n",
        "\n",
        "fig, ax = plt.subplots(nrows=6, ncols=2, figsize=(7, 9))\n",
        "fig.suptitle('Scatter plots of log(fx) versus log(relative CPI-index)', fontsize=10)\n",
        "plt.rcParams['font.size'] = 7\n",
        "for index, cpi in enumerate(cpi_log_ratio.columns):\n",
        "    if index <= 5:\n",
        "        sns.scatterplot(ax=ax[index, 0], x=cpi_log_ratio[cpi], y=fx_log.iloc[:, index], label=cpi)\n",
        "        ax[index, 0].legend(loc='lower right', fontsize=7)\n",
        "    else:\n",
        "        sns.scatterplot(ax=ax[(index - 6), 1], x=cpi_log_ratio[cpi], y=fx_log.iloc[:, index], label=cpi)\n",
        "        ax[(index - 6), 1].legend(loc='lower right', fontsize=7)\n",
        "sns.despine()\n",
        "plt.savefig('scatter_fx_cpi.png', dpi=300)\n",
        "plt.show()\n",
        "\n",
        "# %% construct df for log relative productivity index\n",
        "\n",
        "prod_data = data['prod'].set_index('date')\n",
        "prod_data = prod_data.resample('M').last().ffill()\n",
        "\n",
        "prod_new_date_range = pd.date_range(start='1996-01-31', end=end_date_panel, freq='M')\n",
        "prod_reindexed = prod_data.reindex(prod_new_date_range)\n",
        "prod_reindexed = prod_reindexed.ffill()\n",
        "prod_ratio = prod_reindexed.iloc[:, 1:].div(prod_reindexed.usd_prod, axis=0)  # relative to us\n",
        "prod_log_ratio = np.log(prod_ratio).shift(3).dropna()  # quarter lag\n",
        "\n",
        "print(f'prod_log_ratio shape of frame is {prod_log_ratio.shape}, \\n'\n",
        "      f'prod_log_ratio starts at {prod_log_ratio.index.date[0]}, \\n'\n",
        "      f'prod_log_ratio ends at {prod_log_ratio.index.date[-1]}')\n",
        "\n",
        "# %% plot the relative productivity index of each currency for data visualisation\n",
        "\n",
        "fig, ax = plt.subplots(nrows=12, figsize=(7, 9), sharex='all')\n",
        "fig.suptitle('Relative labour productivity index versus USA since 1996', fontsize=10)\n",
        "plt.rcParams['font.size'] = 7\n",
        "for index, prod in enumerate(prod_ratio.columns):\n",
        "    ax[index].plot(prod_ratio[prod], label=prod)\n",
        "    ax[index].legend(loc='upper left', fontsize=7)\n",
        "sns.despine()\n",
        "plt.savefig('relative_prod_chart.png', dpi=300)\n",
        "plt.show()\n",
        "\n",
        "# %% nicer plot of cpi ratio\n",
        "\n",
        "fig.tight_layout()\n",
        "prod_ratio.plot(\n",
        "    subplots=True,\n",
        "    layout=(4, 3),\n",
        "    figsize=(10, 6),\n",
        "    title='Productivity Index ratio vs. US',\n",
        "    cmap='tab20',\n",
        "    sharex=False,\n",
        "    sharey=False,\n",
        "    fontsize=6,\n",
        "    linewidth=1,\n",
        "    legend=True,\n",
        ")\n",
        "sns.despine()\n",
        "plt.show()\n",
        "# %% plot scatter plots of fx_log versus prod_log_ratio\n",
        "\n",
        "fig, ax = plt.subplots(nrows=6, ncols=2, figsize=(7, 9))\n",
        "fig.suptitle('Scatter plots of log(fx) versus log(relative productivity)', fontsize=10)\n",
        "plt.rcParams['font.size'] = 7\n",
        "for index, prod in enumerate(prod_log_ratio.columns):\n",
        "    if index <= 5:\n",
        "        sns.scatterplot(ax=ax[index, 0], x=prod_log_ratio[prod], y=fx_log.iloc[:, index], label=prod)\n",
        "        ax[index, 0].legend(loc='lower right', fontsize=7)\n",
        "    else:\n",
        "        sns.scatterplot(ax=ax[(index - 6), 1], x=prod_log_ratio[prod], y=fx_log.iloc[:, index], label=prod)\n",
        "        ax[(index - 6), 1].legend(loc='lower right', fontsize=7)\n",
        "sns.despine()\n",
        "plt.savefig('scatter_fx_prod.png', dpi=300)\n",
        "plt.show()\n",
        "\n",
        "# %% create individual g9 & cee3 currency panels with loop, then concat afterwards to complete panel set\n",
        "\n",
        "g9_panels = []\n",
        "for index, currency in enumerate(g9_tickers):\n",
        "    panel = fx_log[[g9_tickers[index]]].copy()\n",
        "    panel.rename(columns={currency: 'fx_log'}, inplace=True)\n",
        "    panel['currency'] = currency\n",
        "    panel = panel[['currency', 'fx_log']]\n",
        "    panel['tot_log_ratio'] = tot_log_ratio.iloc[:, index]\n",
        "    panel['gfc_log_ratio'] = gfc_log_ratio.iloc[:, index]\n",
        "    panel['yield_diff'] = g9_yield_diff.iloc[:, index]\n",
        "    panel['cpi_log_ratio'] = cpi_log_ratio.iloc[:, index]\n",
        "    panel['prod_log_ratio'] = prod_log_ratio.iloc[:, index]\n",
        "    g9_panels.append(panel)\n",
        "\n",
        "# unpack each panel dataframe and assign to variable\n",
        "eur_panel, cad_panel, jpy_panel, gbp_panel, sek_panel, nok_panel, chf_panel, aud_panel, nzd_panel = g9_panels\n",
        "\n",
        "cee3_panels = []\n",
        "for index, currency in enumerate(cee3_tickers):\n",
        "    panel = fx_log[[cee3_tickers[index]]].copy()\n",
        "    panel.rename(columns={currency: 'fx_log'}, inplace=True)\n",
        "    panel['currency'] = currency\n",
        "    panel = panel[['currency', 'fx_log']]\n",
        "    panel['tot_log_ratio'] = tot_log_ratio.iloc[:, index + 9]\n",
        "    panel['gfc_log_ratio'] = gfc_log_ratio.iloc[:, index + 9]\n",
        "    panel['yield_diff'] = cee3_yield_diff.iloc[:, index]\n",
        "    panel['cpi_log_ratio'] = cpi_log_ratio.iloc[:, index + 9]\n",
        "    panel['prod_log_ratio'] = prod_log_ratio.iloc[:, index + 9]\n",
        "    panel = panel.loc['2001-01-31':]\n",
        "    cee3_panels.append(panel)\n",
        "\n",
        "pln_panel, huf_panel, czk_panel = cee3_panels\n",
        "\n",
        "# construct total panel data\n",
        "panel_data = pd.concat([eur_panel, cad_panel, jpy_panel, gbp_panel, sek_panel, nok_panel, chf_panel,\n",
        "                        aud_panel, nzd_panel, pln_panel, huf_panel, czk_panel], axis=0)\n",
        "\n",
        "print(f'shape of panel_data is {panel_data.shape}')\n",
        "\n",
        "# %% test for unit root proces (non-stationary) for just one currency as example. All variables\n",
        "\n",
        "for col in eur_panel.columns[1:]:\n",
        "    adf = adfuller(eur_panel[col].dropna())\n",
        "    print(f'{col} has test-statistic of {adf[0]} en p-value of {adf[1]}')\n",
        "\n",
        "# %% get dummies per currency\n",
        "\n",
        "dummies = pd.get_dummies(panel_data.currency)\n",
        "dummies = dummies[['eurusd', 'cadusd', 'jpyusd', 'gbpusd', 'sekusd', 'nokusd', 'chfusd', 'audusd', 'nzdusd',\n",
        "                   'plnusd', 'hufusd', 'czkusd']]\n",
        "\n",
        "panel_data_and_dummies = pd.concat([panel_data, dummies], axis=1)\n",
        "panel_data_and_dummies = panel_data_and_dummies.reset_index()  # make a multiindex df\n",
        "panel_data_and_dummies.set_index(['currency', 'date'], inplace=True)  # outer index is currency, inner is date\n",
        "panel_data_and_dummies.sort_index(inplace=True)  # multi-indices work best if they are sorted for slicing later\n",
        "\n",
        "# %% plot correlation heatmap and cluster-map (correlation as always on differences, never levels)\n",
        "\n",
        "matrix = panel_data_and_dummies[['fx_log', 'tot_log_ratio', 'gfc_log_ratio', 'yield_diff',\n",
        "                                 'cpi_log_ratio', 'prod_log_ratio']].diff().dropna().\\\n",
        "                                 corr(method='pearson')\n",
        "sns.heatmap(matrix)\n",
        "plt.show()\n",
        "sns.clustermap(matrix)\n",
        "plt.show()\n",
        "# %% plot acf of differenced log fx for just one currency:\n",
        "\n",
        "plot_acf(fx_log.eurusd.diff().dropna(), zero=False, lags=12, alpha=0.05)\n",
        "plt.show()\n",
        "\n",
        "# %% plot time-lagged cross pearson correlation between difference response and differenced variables\n",
        "# time-lagged cross correlation should be on differenced series always!\n",
        "panel_data_and_dummies.fx_log.diff().dropna()\n",
        "panel_data_and_dummies.tot_log_ratio.diff().dropna()\n",
        "\n",
        "tot_log_ratio_cross_correl = [cross_correlation(panel_data_and_dummies.fx_log.diff().dropna(),\n",
        "                                                panel_data_and_dummies.tot_log_ratio.diff().dropna(),\n",
        "                                                lag) for lag in range(1, 13)]\n",
        "\n",
        "gfc_log_ratio_cross_correl = [cross_correlation(panel_data_and_dummies.fx_log.diff().dropna(),\n",
        "                                                panel_data_and_dummies.gfc_log_ratio.diff().dropna(),\n",
        "                                                lag) for lag in range(1, 13)]\n",
        "\n",
        "yield_diff_cross_correl = [cross_correlation(panel_data_and_dummies.fx_log.diff().dropna(),\n",
        "                                             panel_data_and_dummies.yield_diff.diff().dropna(),\n",
        "                                             lag) for lag in range(1, 13)]\n",
        "\n",
        "cpi_log_ratio_cross_correl = [cross_correlation(panel_data_and_dummies.fx_log.diff().dropna(),\n",
        "                                                panel_data_and_dummies.cpi_log_ratio.diff().dropna(),\n",
        "                                                lag) for lag in range(1, 13)]\n",
        "\n",
        "prod_log_ratio_cross_correl = [cross_correlation(panel_data_and_dummies.fx_log.diff().dropna(),\n",
        "                                                 panel_data_and_dummies.prod_log_ratio.diff().dropna(),\n",
        "                                                 lag) for lag in range(1, 13)]\n",
        "\n",
        "cross_correl_df = pd.DataFrame({\n",
        "    'time_lags': pd.Series([i for i in range(1, 13)]),\n",
        "    'tot_log_ratio_correl (cor, p)': [np.round((stat[0], stat[1]), 3) for stat in tot_log_ratio_cross_correl],\n",
        "    'gfc_log_ratio_correl (cor, p)': [np.round((stat[0], stat[1]), 3) for stat in gfc_log_ratio_cross_correl],\n",
        "    'yield_diff_correl (cor, p)': [np.round((stat[0], stat[1]), 3) for stat in yield_diff_cross_correl],\n",
        "    'cpi_log_ratio_correl (cor, p)': [np.round((stat[0], stat[1]), 3) for stat in cpi_log_ratio_cross_correl],\n",
        "    'prod_log_ratio_correl (cor, p)': [np.round((stat[0], stat[1]), 3) for stat in prod_log_ratio_cross_correl]\n",
        "})\n",
        "\n",
        "# %% perform the in_sample fixed effect panel regression through lsdv (least-squares dummy variable)\n",
        "\n",
        "formula = 'fx_log ~ tot_log_ratio + gfc_log_ratio + yield_diff + cpi_log_ratio + prod_log_ratio +' \\\n",
        "          'cadusd + jpyusd + gbpusd +sekusd + nokusd + chfusd + audusd + nzdusd + plnusd + hufusd + czkusd'\n",
        "\n",
        "is_model = ols(formula=formula, data=panel_data_and_dummies).fit()\n",
        "print(is_model.summary())\n",
        "\n",
        "# %% test for cointegration using ADF on residuals : test for stationary on the estimated residuals\n",
        "# of the regression that estimates the long run relationship between fx and variables\n",
        "# the residuals are nothing more than the deviations from fair value\n",
        "# if ADF (test for random walk (non-stationary) on residuals shows residuals are stationary=\n",
        "# residuals (=linear combo of all time series) is stationary and series are coint and the residuals (deviations)\n",
        "# are mean-reverting in nature (leash of dog and owner dog is mean-reverting and predictable)\n",
        "\n",
        "residual_stationary_test = adfuller(is_model.resid)\n",
        "print(f'The adf-test on the residuals of our panel regression has a test-statistic '\n",
        "      f'of {residual_stationary_test[0]} and a p-value of {residual_stationary_test[1]}')\n",
        "\n",
        "# %% plot residuals if stationary\n",
        "#  p <0.05 reject the null of a unit root (random walk, non-stationary) and residuals are stationary\n",
        "# then plot residuals to see the stationary (mean reversion proces)\n",
        "\n",
        "is_model.resid.plot(title='residual plot (deviation from fair value, (is it mean-reverting? \\n'\n",
        "                          ' residual = linear combination of all series which is stationary after adf test')\n",
        "plt.show()\n",
        "\n",
        "\n",
        "# %% in_sample predictions: fitted values\n",
        "\n",
        "# multi-index series with fair values predicted in_sample (is)\n",
        "is_predictions = is_model.predict(panel_data_and_dummies)\n",
        "\n",
        "# multi-index df\n",
        "is_predictions_df = panel_data_and_dummies[['fx_log']].copy()\n",
        "is_predictions_df['fx_log_fair_is'] = is_predictions\n",
        "\n",
        "# %% vector error correction model: only cross correl was lag 6 for tot\n",
        "# p_values for monthly are not significant, so we calculate quarterly like UniCredit\n",
        "\n",
        "response_vecm = panel_data_and_dummies.fx_log.diff(3).dropna()  # response is first difference at time t\n",
        "response_vecm.name = 'diff_fx_log'\n",
        "\n",
        "predictors_vecm = panel_data_and_dummies[['tot_log_ratio']]\n",
        "predictors_vecm = sm.add_constant(predictors_vecm)  # add a constant\n",
        "\n",
        "# 6-lag change in tot was relevant in cross-correlation matrix: take diff, lag it 6 periods\n",
        "predictors_vecm.loc[:, 'tot_log_ratio'] = predictors_vecm['tot_log_ratio'].diff().shift(6)\n",
        "\n",
        "# add the residuals from the panel regression and lag them 1 period\n",
        "predictors_vecm['lagged residuals'] = is_model.resid.shift(3)\n",
        "predictors_vecm = predictors_vecm.dropna()\n",
        "\n",
        "# align response again\n",
        "response_vecm = response_vecm.tail(-4)\n",
        "\n",
        "\n",
        "# %% the  vecm model\n",
        "vecm_model = sm.OLS(response_vecm, predictors_vecm).fit()\n",
        "print(vecm_model.summary())\n",
        "\n",
        "# %% out_of_sample prediction warmup\n",
        "\n",
        "WARMUP = 59  # 60 months warmup for expanding regression\n",
        "\n",
        "# %% out_of_sample expanding regressions and fair_value predictions for g9 currencies\n",
        "\n",
        "# Construct panel data for g9 only that will be used for expanding regression & prediction\n",
        "panel_data_and_dummies_g9 = panel_data_and_dummies.loc[(g9_tickers, slice(None)), :].copy()\n",
        "panel_data_and_dummies_g9 = panel_data_and_dummies_g9.sort_index()\n",
        "\n",
        "# construct df for out of sample predictions: holds actual and will hold fair values based on expanding window\n",
        "oos_predictions_g9_df = panel_data_and_dummies.loc[(g9_tickers, slice(None)), ['fx_log']].copy()\n",
        "oos_predictions_g9_df = oos_predictions_g9_df.sort_index()\n",
        "\n",
        "# every period perform a regression on expanding window (warmup 60m), predict for that month, append prediction\n",
        "first_date = panel_data_and_dummies_g9.index.get_level_values(1)[0]\n",
        "\n",
        "for i in range(WARMUP, 323):\n",
        "    rolling_end_date = panel_data_and_dummies_g9.index.get_level_values(1)[i]\n",
        "    expanding_panel = panel_data_and_dummies_g9.loc[(slice(None), slice(first_date, rolling_end_date)), :]\n",
        "\n",
        "    oos_model = ols(formula=formula, data=expanding_panel).fit()\n",
        "    oos_prediction_for_one_date = oos_model.predict(panel_data_and_dummies_g9.loc[(slice(None), rolling_end_date), :])\n",
        "    oos_prediction_for_one_date = oos_prediction_for_one_date.to_frame(name=rolling_end_date)\n",
        "    oos_predictions_g9_df.loc[(slice(None), rolling_end_date), 'fx_log_fair_oos'] = oos_prediction_for_one_date.values\n",
        "\n",
        "# %% out_of_sample expanding regressions and fair_value predictions for cee3 currencies\n",
        "\n",
        "# Construct panel data for cee3 only that will be used for expanding regression & prediction\n",
        "panel_data_and_dummies_cee3 = panel_data_and_dummies.loc[(cee3_tickers, slice(None)), :].copy()\n",
        "panel_data_and_dummies_cee3 = panel_data_and_dummies_cee3.sort_index()\n",
        "\n",
        "# construct df for out of sample predictions: holds actual and will hold fair values based on expanding window\n",
        "oos_predictions_cee3_df = panel_data_and_dummies.loc[(cee3_tickers, slice(None)), ['fx_log']].copy()\n",
        "oos_predictions_cee3_df = oos_predictions_cee3_df.sort_index()\n",
        "\n",
        "# every period perform a regression on expanding window (warmup 60m), predict for that month, append prediction\n",
        "first_date_oos = panel_data_and_dummies_cee3.index.get_level_values(1)[0]\n",
        "\n",
        "for index in range(WARMUP, 266):\n",
        "    rolling_end_date_cee3 = panel_data_and_dummies_cee3.index.get_level_values(1)[index]\n",
        "    expanding_panel_cee3 = panel_data_and_dummies_cee3.loc[(slice(None), slice(first_date_oos,\n",
        "                                                                               rolling_end_date_cee3)), :]\n",
        "    oos_model_cee3 = ols(formula=formula, data=expanding_panel_cee3).fit()\n",
        "    oos_prediction_for_one_date_cee3 = oos_model_cee3.predict(panel_data_and_dummies_cee3.loc[(slice(None),\n",
        "                                                                                               rolling_end_date_cee3),\n",
        "                                                              :])\n",
        "    oos_prediction_for_one_date_cee3 = oos_prediction_for_one_date_cee3.to_frame(name=rolling_end_date_cee3)\n",
        "    oos_predictions_cee3_df.loc[\n",
        "        (slice(None), rolling_end_date_cee3), 'fx_log_fair_oos'] = oos_prediction_for_one_date_cee3.values\n",
        "\n",
        "# %% construct total oos df: concat g9 and cee3\n",
        "\n",
        "oos_predictions_df = pd.concat([oos_predictions_g9_df, oos_predictions_cee3_df], axis=0)\n",
        "oos_predictions_df = oos_predictions_df.sort_index()\n",
        "\n",
        "# %% fair value for eurusd: chart\n",
        "\n",
        "\n",
        "end_of_period_values = []\n",
        "for currency in g12_tickers:\n",
        "    fig, ax = plt.subplots(3, 1, figsize=(10, 10))\n",
        "    fig.tight_layout(pad=5.0)\n",
        "    fig.suptitle(f'{currency}: actual level and long-term fair values (in-and-out-of-sample, beer model)')\n",
        "    fx_actual = np.exp(is_predictions_df.loc[(currency, slice(None)), 'fx_log']).droplevel(level=0)\n",
        "    fx_fair_is = np.exp(is_predictions_df.loc[(currency, slice(None)), 'fx_log_fair_is']).droplevel(level=0)\n",
        "    fx_fair_oos = np.exp(oos_predictions_df.loc[(currency, slice(None)), 'fx_log_fair_oos']).droplevel(level=0)\n",
        "\n",
        "    fx_actual.plot(ax=ax[0], label=f'actual {currency}', legend=True)\n",
        "    fx_fair_is.plot(ax=ax[0], color='orange', label='in-sample, long-term fair value (beer)', legend=True)\n",
        "    fx_fair_oos.plot(ax=ax[0], color='red', label='out-of-sample (expanding window), long-term fair value (beer)',\n",
        "                     legend=True)\n",
        "\n",
        "    deviation_perc_is = fx_actual.div(fx_fair_is).sub(1).mul(100)\n",
        "    deviation_perc_oos = fx_actual.div(fx_fair_oos).sub(1).mul(100)\n",
        "\n",
        "    deviation_perc_is.plot(ax=ax[1], label='in-sample % deviation from fair value (beer)', legend=True)\n",
        "    deviation_perc_oos.plot(ax=ax[1], color='red',\n",
        "                            label='out-of-sample (expanding window) % deviation from fair value ('\n",
        "                                  'beer)', legend=True)\n",
        "\n",
        "    ax[1].set_title(f'{currency}: % deviation versus long-term fair values (in-and-out-of-sample, beer model) (-/+)')\n",
        "    ax[1].set_ylabel('% deviation (-/+)')\n",
        "    ax[1].axhline(0, color='red', linestyle='--')\n",
        "\n",
        "    deviation_z_is = stats.zscore(deviation_perc_is)\n",
        "    deviation_z_oos = expanding_z_score(deviation_perc_oos)\n",
        "    deviation_z_is.plot(ax=ax[2], label='in-sample z-score deviation from fair value (beer)', legend=True)\n",
        "    deviation_z_oos.plot(ax=ax[2], color='red', label='out-of-sample (expanding window) z-score deviation '\n",
        "                                                      '(expanding window again) from fair value '\n",
        "                                                      '(beer)', legend=True)\n",
        "    ax[2].set_title(f'{currency}: z-score deviation versus long-term fair values (in-and-out-of-sample, beer model')\n",
        "    ax[2].set_ylabel('z-score deviation (-/+)')\n",
        "    ax[2].axhline(0, color='red', linestyle='--')\n",
        "\n",
        "    sns.despine()\n",
        "    plt.show()\n",
        "\n",
        "    end_of_period_values.append((currency, np.round(deviation_perc_oos[-1], 2), np.round(deviation_z_oos[-1], 2)))\n",
        "\n",
        "\n",
        "# %% random\n",
        "\n",
        "end_of_period_df = pd.DataFrame(end_of_period_values, columns=['currency', 'deviation in %', 'deviation in z-score'])\n",
        "\n",
        "#%%"
      ]
    }
  ]
}